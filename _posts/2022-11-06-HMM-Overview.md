---
layout: post
title: HMM Overview
tags: [NLP]
---

Note: This post aims to give a high-level overview of the hidden Markov model. Hence, some notations are not very rigorously defined and some technical/mathematical detail is omitted. <s>For a more in-depth version of HMM derivation, please see this post; for a more in-depth derivation of the EM algorithm, please see this post.</s>

## Introduction

The **hidden Markov model** (HMM) is a statistical model that assumes the sequence of observed data (evidence) is generated by a sequence of latent states under a Markov chain. It can be viewed as a sequence of (directed) probablisitc graphical models.

The two key components of a HMM are:

1). The **transition probabilities**, i.e. $P(S_{t+1} = s^\prime | S_{t} = s)$;

2). The **emission probabilities**, i.e. $P(X_{t} = w | S_{t} = s)$.

where $S_t$ denotes the random variable of the hidden state at time $t$, and $X_t$ denotes the randome variable of the observation at time $t$.

Note that by the first-order Markov assumption of the model:

1). $P(S_{t+1} = s^\prime | S_{t} = s) = P(S_{t+1} = s^\prime | S_{1} = s_{1}, S_{2} = s_{2}, \cdots, S_{t} = s)$, that is, the probability of $S_t = s^\prime$ is independent of all previous hidden states (and observations) given $S_{t} = s$;

2). $P(X_{t} = w | S_{t} = s) = P(X_{t} = w | s_{1:T}, x_{1:T})$, that is, the probability of $X_t$ is independet of all other random variables in the model given $S_t = s$.

## Inference

Given a HMM, we would like to use it to do *inference*, i.e. given the transition kernel and the emission probabilities, we would like to compute certain probabilities. For instance, the derivation below shows how to compute the joint probability of a sequence of observations with length $T$, $x_{1:T}$, and a sequence of hidden states (also with length $T$), $s_{1:T}$, i.e.

$$
\begin{align*}
P(s_{1:T}, x_{1:T}) &= P(x_1 | x_{2:T}, s_{1:T}) P(x_{2:T}, s_{1:T})\\
&= P(x_1 | s_{1}) P(x_{2:T}, s_{1:T})\\
&= P(x_1 | s_{1}) P(x_{2} | x_{3:T}, s_{1:T}) P(x_{3:T}, s_{1:T})\\
&= P(x_1 | s_{1}) P(x_{2} | s_{2}) P(x_{3:T}, s_{1:T})\\
&\ \ \vdots\\
&= P(x_1 | s_{1}) P(x_{2} | s_{2}) \cdots P(x_{T}, s_{T}) P(s_{1:T})\\
&= \prod_{t = 1}^T P(x_t | s_t) P(s_{T} | s_{1:T - 1}) P(s_{1:T - 1})\\
&= \prod_{t = 1}^T P(x_t | s_t) P(s_{T} | s_{T - 1}) P(s_{1:T - 1} | s_{1:T - 2}) P(s_{1:T - 2})\\
&\ \ \vdots\\
&= \prod_{t = 1}^T P(x_t | s_t) P(s_{T} | s_{T - 1}) P(s_{1:T - 1} | s_{T - 2}) \cdots P(s_2 | s_1) P(s_1)\\
&= P(s_1) \prod_{t = 1}^T P(x_t | s_t) \prod_{t = 1}^{T - 1} P(s_{t + 1} | s_{t})
\end{align*}
$$

The joint probability described above can be interpreted as the probability of a path in the "trellis". A common application of HMM is to compute find the "best path", i.e. the path with the maximum probability or minimum negative log probability. To do that, we usually apply the **Viterbi algorithm** (which is essentially the Dijkstra's algorithm if we view the arcs in the trellis as edges in a graph and transition/emission probabilities as state/edge weights), which yields the best path in polynomial time using dynamic programming.

## Learning

A natural question at this point would be, where did the transition probablities and emission probabilities come from? A nice thing about HMM is that its parameters, i.e. the transition/emission probabilities, can be efficiently estimated. The process of determining the best parameters for the model is sometimes called **learning** or parameter estimation.

Traditionally, there are two different scenarios, namely the **supervised** and **unsupervised** case (actually there does exist something in-between called the "semi-supervised" case, which effectively is a mixture of both).

### Supervised Learning

In the supervised case, the data is given in pairs of $(\vec{x}^{(i)}, \vec{s}^{(i)})$, or equivalently, we are provided with the observations as well as their associated hidden states. For this case, we can simply use the maximum likelihood estimate (MLE), that is, we are trying to maximize:

$$
P(\vec{x}, \vec{s})
$$

which simply gives:

$$
\begin{align*}
\displaystyle P(s^\prime | s) &= \frac{c(s \rightarrow s^\prime)}{c(s)} \\
\displaystyle P(w | s) &= \frac{c(w | s)}{c(s)}
\end{align*}
$$

in which $c(s \rightarrow s^\prime)$ denotes the count of the transition $s \rightarrow s^\prime$ that takes place in the training data, $c(w | s)$ denotes the count of the emission $w | s$ and $c(s)$ denotes the count of state $s$ in the training data.

### Unsupervised Learning

In the unsupervised setting, the data we have access to has only the observations. This is more common in reality, since human annotations are very expensive to obtain especially when the size of the data scales. The principle of our learning remains unchanged, as we are still trying to maximize the likelihood of the data. However, this time we are maximizing the **incomplete data likelihood**, i.e.

$$P(\vec{x}) = \sum_{\vec{s}} P(\vec{x}, \vec{s})$$

In order to maximize the this probability, we often use the **expectation maximization** (EM) algorithm to iteratively finds a set of parameters. For the simplicity of this post, we only provide the resulting parameter update equation, which is also known as the **Baum-Welch** algorithm:

$$
\begin{align*}
    P(s^\prime | s) &= \displaystyle \frac{\displaystyle \sum_{t = 1}^{T - 1} P(S_t = s^\prime, S_{t-1} = s | x_{1:T})}{\displaystyle \sum_{t=1}^{T-1} P(S_{t-1} = s | x_{1:T})}\\
    P(w | s) &= \displaystyle \frac{\displaystyle \sum_{t = 1}^{T} P(S_t = s | x_{1:T}) \mathbb{I}(x_t = w)}{\displaystyle \sum_{t=1}^{T} P(S_t = s | x_{1:T})}
\end{align*}
$$

where $\mathbb{I}$ is the indicator function.
